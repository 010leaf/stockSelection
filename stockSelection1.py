import tushare as ts
import pandas as pd
import streamlit as st
from datetime import datetime, timedelta
import time
import random
import os
import pickle

# -------------------------- æ ¸å¿ƒé…ç½®ï¼ˆTushareæˆæƒ+ç­›é€‰è§„åˆ™ï¼‰ --------------------------
CONFIG = {
    "tushare_token": "ä½ çš„token",  # æ›¿æ¢ä¸ºä½ çš„çœŸå®TOKENï¼
    "limit_up_price_pct": 9.8,
    "limit_down_price_pct": -9.8,
    "trend_days": 60,
    "trend_up_pct": 30,
    "trend_volatility_pct": 25,
    "capital_flow_days": 5,
    "min_stock_price": 3.0,
    "exclude_boards": ["åˆ›ä¸šæ¿", "ç§‘åˆ›æ¿"],  # æ’é™¤åˆ›ä¸šæ¿/ç§‘åˆ›æ¿
    "batch_size": 10,
    "cache_expire_hours": 24  # çœŸå®æ•°æ®ç¼“å­˜24å°æ—¶
}

# -------------------------- 1. Tushareåˆå§‹åŒ–ï¼ˆæ ¸å¿ƒï¼‰ --------------------------
def init_tushare():
    """åˆå§‹åŒ–Tushareï¼Œç¡®ä¿æˆæƒæˆåŠŸ"""
    try:
        ts.set_token(CONFIG["tushare_token"])
        pro = ts.pro_api()
        # æµ‹è¯•è¿æ¥æ˜¯å¦æ­£å¸¸
        pro.stock_basic(exchange='', list_status='L', fields='ts_code,symbol,name,industry,list_date')
        st.success("âœ… TushareæˆæƒæˆåŠŸï¼Œå¯è·å–çœŸå®è‚¡ç¥¨æ•°æ®")
        return pro
    except Exception as e:
        st.error(f"âŒ Tushareåˆå§‹åŒ–å¤±è´¥ï¼š{e}")
        st.info("ğŸ’¡ è¯·æ£€æŸ¥ï¼š1.TOKENæ˜¯å¦æ­£ç¡® 2.ç½‘ç»œæ˜¯å¦æ­£å¸¸ 3.Tushareè´¦å·æ˜¯å¦å®åè®¤è¯")
        return None

# -------------------------- 2. ç¼“å­˜å·¥å…·ï¼ˆå‡å°‘é‡å¤è¯·æ±‚ï¼‰ --------------------------
def get_cache_file_path():
    cache_dir = "tushare_stock_cache"
    if not os.path.exists(cache_dir):
        os.makedirs(cache_dir)
    return os.path.join(cache_dir, "tushare_stock_data.pkl")

def load_cache():
    cache_path = get_cache_file_path()
    if os.path.exists(cache_path):
        try:
            with open(cache_path, 'rb') as f:
                return pickle.load(f)
        except:
            return {}
    return {}

def save_cache(cache_data):
    cache_path = get_cache_file_path()
    try:
        with open(cache_path, 'wb') as f:
            pickle.dump(cache_data, f)
    except Exception as e:
        st.warning(f"âš ï¸ ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")

# -------------------------- 3. è·å–çœŸå®è‚¡ç¥¨åŸºç¡€æ•°æ®ï¼ˆæ ¸å¿ƒï¼‰ --------------------------
def get_all_qualified_stocks(pro):
    """ä»Tushareè·å–ï¼šéåˆ›ä¸šæ¿/éç§‘åˆ›æ¿+éETF+è‚¡ä»·â‰¥3å…ƒçš„çœŸå®è‚¡ç¥¨æ•°æ®"""
    cache_data = load_cache()
    cache_key = "qualified_stocks"
    
    # ä¼˜å…ˆè¯»å–ç¼“å­˜ï¼ˆ24å°æ—¶å†…æœ‰æ•ˆï¼‰
    if cache_key in cache_data:
        cached_time, stock_df = cache_data[cache_key]
        if (datetime.now() - datetime.fromisoformat(cached_time)).total_seconds() < CONFIG["cache_expire_hours"] * 3600:
            st.info("ğŸ“¦ ä½¿ç”¨ç¼“å­˜çš„çœŸå®è‚¡ç¥¨æ•°æ®ï¼ˆ24å°æ—¶å†…ï¼‰")
            return stock_df
    
    try:
        st.info("ğŸ” ä»Tushareè·å–å…¨å¸‚åœºAè‚¡åŸºç¡€æ•°æ®...")
        # 1. è·å–æ‰€æœ‰ä¸Šå¸‚Aè‚¡åŸºç¡€ä¿¡æ¯
        stock_basic = pro.stock_basic(
            exchange='',
            list_status='L',  # ä»…ä¸Šå¸‚çŠ¶æ€
            fields='ts_code,symbol,name,industry,market,list_date,exchange'
        )
        
        # 2. æ ¸å¿ƒç­›é€‰ï¼šæ’é™¤åˆ›ä¸šæ¿/ç§‘åˆ›æ¿
        # Tushareçš„marketå­—æ®µå¯¹åº”ï¼šä¸»æ¿/åˆ›ä¸šæ¿/ç§‘åˆ›æ¿/ä¸­å°æ¿/åŒ—äº¤æ‰€
        stock_basic = stock_basic[~stock_basic["market"].isin(["åˆ›ä¸šæ¿", "ç§‘åˆ›æ¿"])]
        
        # 3. æ’é™¤ETFï¼ˆåç§°å«ETF/etfï¼‰
        stock_basic = stock_basic[~stock_basic["name"].str.contains("ETF|etf", na=False, regex=True)]
        
        # 4. è·å–æœ€æ–°è‚¡ä»·ï¼ˆçœŸå®è¡Œæƒ…ï¼‰
        st.info("ğŸ“¡ è·å–æœ€æ–°è‚¡ä»·æ•°æ®...")
        # è·å–å½“æ—¥è¡Œæƒ…ï¼ˆTushareçš„trade_dateä¸ºYYYYMMDDï¼‰
        trade_date = pro.trade_cal(exchange='', start_date=datetime.now().strftime("%Y%m%d"), end_date=datetime.now().strftime("%Y%m%d"), is_open=1)
        if not trade_date.empty:
            trade_date = trade_date.iloc[0]["cal_date"]
        else:
            # éäº¤æ˜“æ—¥å–æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥
            trade_date = pro.trade_cal(exchange='', start_date=(datetime.now()-timedelta(days=7)).strftime("%Y%m%d"), end_date=datetime.now().strftime("%Y%m%d"), is_open=1).iloc[-1]["cal_date"]
        
        # æ‰¹é‡è·å–è¡Œæƒ…æ•°æ®
        ts_codes = stock_basic["ts_code"].tolist()
        price_df = pd.DataFrame()
        # åˆ†æ‰¹è¯·æ±‚ï¼ˆé¿å…å•æ¬¡è¯·æ±‚è¿‡å¤šï¼‰
        batch_size = 500
        for i in range(0, len(ts_codes), batch_size):
            batch_codes = ts_codes[i:i+batch_size]
            batch_price = pro.daily(ts_code=','.join(batch_codes), trade_date=trade_date)
            price_df = pd.concat([price_df, batch_price], ignore_index=True)
            time.sleep(0.5)  # Tushareå…è´¹ç‰ˆé™é€Ÿ
        
        # åˆå¹¶è‚¡ä»·æ•°æ®
        price_df.rename(columns={"close": "æœ€æ–°ä»·æ ¼(å…ƒ)", "pct_chg": "æ¶¨è·Œå¹…(%)", "vol": "æˆäº¤é‡(æ‰‹)", "amount": "æˆäº¤é¢(ä¸‡å…ƒ)"}, inplace=True)
        # æˆäº¤é‡å•ä½è½¬æ¢ï¼šTushareçš„volæ˜¯æ‰‹ï¼Œæ— éœ€è½¬æ¢ï¼›amountæ˜¯å…ƒâ†’è½¬ä¸‡å…ƒ
        price_df["æˆäº¤é¢(ä¸‡å…ƒ)"] = price_df["æˆäº¤é¢(ä¸‡å…ƒ)"] / 10000
        
        # åˆå¹¶åŸºç¡€ä¿¡æ¯å’Œè‚¡ä»·
        stock_df = pd.merge(
            stock_basic,
            price_df[["ts_code", "æœ€æ–°ä»·æ ¼(å…ƒ)", "æ¶¨è·Œå¹…(%)", "æˆäº¤é‡(æ‰‹)", "æˆäº¤é¢(ä¸‡å…ƒ)"]],
            on="ts_code",
            how="left"
        )
        
        # 5. ç­›é€‰è‚¡ä»·â‰¥3å…ƒï¼ˆå‰”é™¤æ— è‚¡ä»·æ•°æ®çš„è‚¡ç¥¨ï¼‰
        stock_df = stock_df[stock_df["æœ€æ–°ä»·æ ¼(å…ƒ)"].notna()]
        stock_df = stock_df[stock_df["æœ€æ–°ä»·æ ¼(å…ƒ)"] >= CONFIG["min_stock_price"]]
        
        # 6. å­—æ®µé‡å‘½å/æ•´ç†ï¼ˆé€‚é…å±•ç¤ºï¼‰
        stock_df.rename(
            columns={
                "symbol": "è‚¡ç¥¨ä»£ç ",
                "name": "è‚¡ç¥¨åç§°",
                "market": "æ‰€å±æ¿å—",
                "industry": "æ‰€å±è¡Œä¸š",
                "exchange": "äº¤æ˜“æ‰€",
                "ts_code": "TSä»£ç "
            },
            inplace=True
        )
        # äº¤æ˜“æ‰€åç§°æ ‡å‡†åŒ–
        stock_df["äº¤æ˜“æ‰€"] = stock_df["äº¤æ˜“æ‰€"].map({"SSE": "ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€", "SZSE": "æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€", "BSE": "åŒ—äº¬è¯åˆ¸äº¤æ˜“æ‰€"})
        
        # 7. ç¼“å­˜æ•°æ®
        cache_data[cache_key] = (datetime.now().isoformat(), stock_df)
        save_cache(cache_data)
        
        st.success(f"âœ… æˆåŠŸè·å– {len(stock_df)} åªç¬¦åˆæ¡ä»¶çš„çœŸå®è‚¡ç¥¨æ•°æ®ï¼ˆéåˆ›ä¸šæ¿/éç§‘åˆ›æ¿+éETF+è‚¡ä»·â‰¥{CONFIG['min_stock_price']}å…ƒï¼‰")
        return stock_df
    
    except Exception as e:
        st.error(f"âŒ è·å–çœŸå®è‚¡ç¥¨æ•°æ®å¤±è´¥ï¼š{e}")
        st.info("ğŸ’¡ Tushareå…è´¹ç‰ˆé™åˆ¶ï¼š1.æ¯åˆ†é’Ÿæœ€å¤š60æ¬¡è¯·æ±‚ 2.éƒ¨åˆ†å­—æ®µéœ€å‡çº§æƒé™")
        return pd.DataFrame()

# -------------------------- 4. è·å–çœŸå®æ—¥çº¿æ•°æ®ï¼ˆç”¨äºè¿›é˜¶ç­›é€‰ï¼‰ --------------------------
def get_real_daily_data(pro, ts_code, start_date, end_date):
    """ä»Tushareè·å–å•åªè‚¡ç¥¨çš„çœŸå®æ—¥çº¿æ•°æ®"""
    cache_data = load_cache()
    cache_key = f"daily_{ts_code}_{start_date}_{end_date}"
    
    # ç¼“å­˜ä¼˜å…ˆ
    if cache_key in cache_data:
        cached_time, daily_df = cache_data[cache_key]
        if (datetime.now() - datetime.fromisoformat(cached_time)).total_seconds() < CONFIG["cache_expire_hours"] * 3600:
            return daily_df
    
    try:
        # è½¬æ¢æ—¥æœŸæ ¼å¼ï¼ˆTushareä¸ºYYYYMMDDï¼‰
        start = start_date.replace("-", "") if "-" in start_date else start_date
        end = end_date.replace("-", "") if "-" in end_date else end_date
        
        daily_df = pro.daily(
            ts_code=ts_code,
            start_date=start,
            end_date=end
        )
        
        if not daily_df.empty:
            # å­—æ®µæ•´ç†
            daily_df.rename(columns={"close": "close", "open": "open", "high": "high", "low": "low", "amount": "amount"}, inplace=True)
            daily_df["pct_change"] = daily_df["pct_chg"]  # æ¶¨è·Œå¹…
            daily_df["trade_date"] = daily_df["trade_date"]
            
            # ç¼“å­˜æ•°æ®
            cache_data[cache_key] = (datetime.now().isoformat(), daily_df)
            save_cache(cache_data)
            
            return daily_df
        else:
            st.warning(f"âš ï¸ {ts_code} æ— æ—¥çº¿æ•°æ®ï¼ˆ{start_date}è‡³{end_date}ï¼‰")
            return pd.DataFrame()
    
    except Exception as e:
        st.warning(f"âš ï¸ è·å– {ts_code} æ—¥çº¿æ•°æ®å¤±è´¥ï¼š{e}")
        return pd.DataFrame()

# -------------------------- 5. è¿›é˜¶ç­›é€‰é€»è¾‘ï¼ˆåŸºäºçœŸå®æ•°æ®ï¼‰ --------------------------
def calculate_limit_up_status(pro, ts_code, trade_date, è¿ç»­æ¶¨åœå¤©æ•°=2):
    """è®¡ç®—è¿æ¿çŠ¶æ€ï¼ˆçœŸå®æ•°æ®ï¼‰"""
    try:
        # è·å–æœ€è¿‘Nä¸ªäº¤æ˜“æ—¥çš„æ—¥çº¿æ•°æ®
        start_date = (datetime.strptime(trade_date, "%Y%m%d") - timedelta(days=è¿ç»­æ¶¨åœå¤©æ•°+2)).strftime("%Y%m%d")
        daily_df = get_real_daily_data(pro, ts_code, start_date, trade_date)
        
        if daily_df.empty or len(daily_df) < è¿ç»­æ¶¨åœå¤©æ•°:
            return False, 0
        
        # æŒ‰äº¤æ˜“æ—¥æœŸé™åºæ’åˆ—
        daily_df = daily_df.sort_values("trade_date", ascending=False).reset_index(drop=True)
        æ¶¨åœå¤©æ•° = 0
        
        for i in range(è¿ç»­æ¶¨åœå¤©æ•°):
            if i >= len(daily_df):
                break
            # æ¶¨åœåˆ¤æ–­ï¼šæ¶¨è·Œå¹…â‰¥9.8%ï¼ˆä¸»æ¿/ä¸­å°æ¿/åŒ—äº¤æ‰€æ¶¨åœæ¿10%ï¼‰
            if daily_df.iloc[i]["pct_chg"] >= CONFIG["limit_up_price_pct"]:
                æ¶¨åœå¤©æ•° += 1
            else:
                break
        
        return æ¶¨åœå¤©æ•° >= è¿ç»­æ¶¨åœå¤©æ•°, æ¶¨åœå¤©æ•°
    except Exception as e:
        st.warning(f"âš ï¸ è®¡ç®— {ts_code} è¿æ¿çŠ¶æ€å¤±è´¥ï¼š{e}")
        return False, 0

def calculate_trend_status(pro, ts_code, trade_date):
    """è®¡ç®—è¶‹åŠ¿çŠ¶æ€ï¼ˆçœŸå®æ•°æ®ï¼‰"""
    try:
        # è·å–60å¤©å‰çš„æ—¥æœŸ
        start_date = (datetime.strptime(trade_date, "%Y%m%d") - timedelta(days=CONFIG["trend_days"])).strftime("%Y%m%d")
        daily_df = get_real_daily_data(pro, ts_code, start_date, trade_date)
        
        if daily_df.empty or len(daily_df) < CONFIG["trend_days"]:
            return False, 0, 0
        
        daily_df = daily_df.sort_values("trade_date").reset_index(drop=True)
        start_close = daily_df.iloc[0]["close"]
        end_close = daily_df.iloc[-1]["close"]
        
        # 60æ—¥æ¶¨å¹…
        trend_up_pct = (end_close - start_close) / start_close * 100 if start_close != 0 else 0
        
        # è®¡ç®—å‡çº¿
        daily_df["ma5"] = daily_df["close"].rolling(window=5).mean().fillna(0)
        daily_df["ma20"] = daily_df["close"].rolling(window=20).mean().fillna(0)
        last_ma5 = daily_df.iloc[-1]["ma5"]
        last_ma20 = daily_df.iloc[-1]["ma20"]
        
        # è®¡ç®—æ³¢åŠ¨ç‡
        daily_df["volatility"] = daily_df.apply(
            lambda row: (row["high"] - row["low"]) / row["open"] * 100 if row["open"] != 0 else 0,
            axis=1
        )
        avg_volatility = daily_df.tail(20)["volatility"].mean()
        
        # è¶‹åŠ¿åˆ¤æ–­
        is_trend = (trend_up_pct >= CONFIG["trend_up_pct"]) and \
                   (last_ma5 > last_ma20) and \
                   (avg_volatility <= CONFIG["trend_volatility_pct"])
        
        return is_trend, round(trend_up_pct, 2), round(avg_volatility, 2)
    except Exception as e:
        st.warning(f"âš ï¸ è®¡ç®— {ts_code} è¶‹åŠ¿çŠ¶æ€å¤±è´¥ï¼š{e}")
        return False, 0, 0

def filter_all_stocks(pro, stock_basic, stock_type, board_filter="å…¨éƒ¨"):
    """è¿›é˜¶ç­›é€‰ï¼ˆåŸºäºçœŸå®æ•°æ®ï¼‰"""
    if stock_basic.empty:
        st.error("âŒ æ— ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨æ•°æ®")
        return pd.DataFrame()
    
    # è·å–æœ€æ–°äº¤æ˜“æ—¥
    trade_date = pro.trade_cal(exchange='', start_date=datetime.now().strftime("%Y%m%d"), end_date=datetime.now().strftime("%Y%m%d"), is_open=1)
    trade_date = trade_date.iloc[0]["cal_date"] if not trade_date.empty else datetime.now().strftime("%Y%m%d")
    
    st.write(f"ğŸ“… ç­›é€‰æ—¥æœŸï¼š{trade_date} | ğŸ“ˆ ç­›é€‰ç±»å‹ï¼š{stock_type} | ğŸ¯ æ¿å—è¿‡æ»¤ï¼š{board_filter}")
    
    result_list = []
    total = len(stock_basic)
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # åˆ†æ‰¹å¤„ç†
    batch_size = CONFIG["batch_size"]
    for batch_idx in range(0, total, batch_size):
        batch = stock_basic.iloc[batch_idx:batch_idx+batch_size]
        status_text.write(f"ğŸ”„ å¤„ç†ç¬¬{batch_idx//batch_size + 1}æ‰¹ / å…±{total//batch_size + 1}æ‰¹ï¼ˆ{batch_idx+1}-{min(batch_idx+batch_size, total)}/{total}ï¼‰")
        
        for idx, row in batch.iterrows():
            ts_code = row["TSä»£ç "]
            symbol = row["è‚¡ç¥¨ä»£ç "]
            try:
                res_row = row.copy()
                
                if stock_type in ["å…¨éƒ¨", "è¿æ¿ç¥¨"]:
                    is_lianban, days = calculate_limit_up_status(pro, ts_code, trade_date)
                    res_row["è¿æ¿å¤©æ•°"] = days
                    if is_lianban:
                        res_row["è‚¡ç¥¨ç±»å‹"] = "è¿æ¿ç¥¨"
                        result_list.append(res_row)
                
                if stock_type in ["å…¨éƒ¨", "è¶‹åŠ¿ç¥¨"]:
                    is_trend, up_pct, vol = calculate_trend_status(pro, ts_code, trade_date)
                    res_row["60æ—¥æ¶¨å¹…(%)"] = up_pct
                    res_row["20æ—¥æ³¢åŠ¨ç‡(%)"] = vol
                    if is_trend:
                        res_row["è‚¡ç¥¨ç±»å‹"] = "è¶‹åŠ¿ç¥¨"
                        result_list.append(res_row)
                
                if stock_type == "å…¨éƒ¨" and res_row.name not in [r.name for r in result_list]:
                    res_row["è‚¡ç¥¨ç±»å‹"] = "æœªåŒ¹é…"
                    result_list.append(res_row)
            
            except Exception as e:
                st.warning(f"âš ï¸ å¤„ç† {symbol} å¤±è´¥ï¼š{e}")
                continue
        
        progress_bar.progress(min((batch_idx+batch_size)/total, 1.0))
        time.sleep(1)  # Tushareé™é€Ÿ
    
    progress_bar.empty()
    status_text.empty()
    
    result_df = pd.DataFrame(result_list)
    if not result_df.empty:
        result_df = result_df.fillna("")
        # æ¿å—è¿‡æ»¤
        if board_filter != "å…¨éƒ¨" and "æ‰€å±æ¿å—" in result_df.columns:
            result_df = result_df[result_df["æ‰€å±æ¿å—"] == board_filter]
        result_df = result_df.drop_duplicates(subset=["è‚¡ç¥¨ä»£ç "], keep="first")
    
    return result_df

# -------------------------- 6. Webé¡µé¢å±•ç¤ºï¼ˆçœŸå®æ•°æ®ï¼‰ --------------------------
def main():
    st.set_page_config(page_title="è‚¡ç¥¨é€‰è‚¡ç³»ç»Ÿï¼ˆTushareçœŸå®æ•°æ®ç‰ˆï¼‰", page_icon="ğŸ“Š", layout="wide")
    st.title("ğŸ“Š è‚¡ç¥¨é€‰è‚¡ç³»ç»Ÿï¼ˆTushareçœŸå®æ•°æ®ç‰ˆï¼‰")
    st.subheader("âœ… éåˆ›ä¸šæ¿/éç§‘åˆ›æ¿+éETF+è‚¡ä»·â‰¥3å…ƒ | åŸºäºTushareçœŸå®å¸‚åœºæ•°æ®")
    st.divider()
    
    # 1. åˆå§‹åŒ–Tushare
    pro = init_tushare()
    if pro is None:
        return
    
    # 2. è·å–å¹¶å±•ç¤ºç¬¦åˆæ¡ä»¶çš„çœŸå®è‚¡ç¥¨åˆ—è¡¨
    st.header("ğŸ“‹ ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨åˆ—è¡¨ï¼ˆçœŸå®æ•°æ®ï¼‰")
    with st.spinner("âŒ› åŠ è½½çœŸå®è‚¡ç¥¨æ•°æ®..."):
        stock_basic = get_all_qualified_stocks(pro)
    
    if not stock_basic.empty:
        # å±•ç¤ºæ ¸å¿ƒå­—æ®µï¼šè‚¡ç¥¨ä»£ç ã€åç§°ã€æ‰€å±æ¿å—ã€äº¤æ˜“æ‰€ã€æœ€æ–°ä»·æ ¼ã€æ¶¨è·Œå¹…ã€æˆäº¤é‡ã€æ‰€å±è¡Œä¸š
        display_cols = ["è‚¡ç¥¨ä»£ç ", "è‚¡ç¥¨åç§°", "æ‰€å±æ¿å—", "äº¤æ˜“æ‰€", "æœ€æ–°ä»·æ ¼(å…ƒ)", "æ¶¨è·Œå¹…(%)", "æˆäº¤é‡(æ‰‹)", "æ‰€å±è¡Œä¸š"]
        st.dataframe(
            stock_basic[display_cols],
            use_container_width=True,
            hide_index=True,
            column_config={
                "æœ€æ–°ä»·æ ¼(å…ƒ)": st.column_config.NumberColumn("æœ€æ–°ä»·æ ¼(å…ƒ)", format="%.2f"),
                "æ¶¨è·Œå¹…(%)": st.column_config.NumberColumn("æ¶¨è·Œå¹…(%)", format="%.2f"),
                "æˆäº¤é‡(æ‰‹)": st.column_config.NumberColumn("æˆäº¤é‡(æ‰‹)", format="%d"),
                "è‚¡ç¥¨ä»£ç ": st.column_config.TextColumn("è‚¡ç¥¨ä»£ç ", width="small"),
                "è‚¡ç¥¨åç§°": st.column_config.TextColumn("è‚¡ç¥¨åç§°", width="medium")
            },
            height=500
        )
        st.info(f"ğŸ“Š å…±å±•ç¤º {len(stock_basic)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ï¼ˆéåˆ›ä¸šæ¿/éç§‘åˆ›æ¿+éETF+è‚¡ä»·â‰¥{CONFIG['min_stock_price']}å…ƒï¼‰")
    else:
        st.error("âŒ æ— æ³•è·å–ç¬¦åˆæ¡ä»¶çš„çœŸå®è‚¡ç¥¨æ•°æ®")
        return
    
    st.divider()
    
    # 3. è¿›é˜¶ç­›é€‰åŠŸèƒ½
    st.header("ğŸ”§ è¿›é˜¶ç­›é€‰ï¼ˆåŸºäºçœŸå®æ—¥çº¿æ•°æ®ï¼‰")
    col1, col2 = st.columns(2)
    with col1:
        stock_type = st.selectbox("ç­›é€‰ç±»å‹", ["å…¨éƒ¨", "è¿æ¿ç¥¨", "è¶‹åŠ¿ç¥¨"], index=0)
    with col2:
        # æŒ‰æ‰€å±æ¿å—ç­›é€‰
        all_boards = ["å…¨éƒ¨"] + list(set(stock_basic["æ‰€å±æ¿å—"].tolist()))
        board_filter = st.selectbox("æ‰€å±æ¿å—", all_boards, index=0)
    
    # ç­›é€‰æŒ‰é’®
    if st.button("ğŸš€ å¼€å§‹è¿›é˜¶ç­›é€‰", type="primary"):
        with st.spinner(f"âŒ› æ­£åœ¨ç­›é€‰ {len(stock_basic)} åªè‚¡ç¥¨..."):
            result_df = filter_all_stocks(pro, stock_basic, stock_type, board_filter)
        
        st.success(f"âœ… ç­›é€‰å®Œæˆï¼å…±æ‰¾åˆ° {len(result_df)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
        st.divider()
        
        # å±•ç¤ºç­›é€‰ç»“æœ
        st.header("ğŸ¯ ç­›é€‰ç»“æœï¼ˆçœŸå®æ•°æ®ï¼‰")
        if not result_df.empty:
            display_cols = ["è‚¡ç¥¨ä»£ç ", "è‚¡ç¥¨åç§°", "æ‰€å±æ¿å—", "äº¤æ˜“æ‰€", "æœ€æ–°ä»·æ ¼(å…ƒ)", "æ¶¨è·Œå¹…(%)", "æ‰€å±è¡Œä¸š"]
            # è¡¥å……ç­›é€‰ç»´åº¦å­—æ®µ
            if stock_type == "è¿æ¿ç¥¨":
                display_cols.append("è¿æ¿å¤©æ•°")
            elif stock_type == "è¶‹åŠ¿ç¥¨":
                display_cols.extend(["60æ—¥æ¶¨å¹…(%)", "20æ—¥æ³¢åŠ¨ç‡(%)"])
            
            st.dataframe(
                result_df[display_cols],
                use_container_width=True,
                hide_index=True,
                column_config={
                    "æœ€æ–°ä»·æ ¼(å…ƒ)": st.column_config.NumberColumn("æœ€æ–°ä»·æ ¼(å…ƒ)", format="%.2f"),
                    "æ¶¨è·Œå¹…(%)": st.column_config.NumberColumn("æ¶¨è·Œå¹…(%)", format="%.2f"),
                    "60æ—¥æ¶¨å¹…(%)": st.column_config.NumberColumn("60æ—¥æ¶¨å¹…(%)", format="%.2f"),
                    "20æ—¥æ³¢åŠ¨ç‡(%)": st.column_config.NumberColumn("20æ—¥æ³¢åŠ¨ç‡(%)", format="%.2f"),
                    "è¿æ¿å¤©æ•°": st.column_config.NumberColumn("è¿æ¿å¤©æ•°", format="%d")
                }
            )
            
            # å¯¼å‡ºçœŸå®æ•°æ®
            csv_data = result_df.to_csv(index=False, encoding="utf-8-sig")
            st.download_button(
                label="ğŸ“¥ å¯¼å‡ºç­›é€‰ç»“æœï¼ˆçœŸå®æ•°æ®ï¼‰",
                data=csv_data,
                file_name=f"çœŸå®è‚¡ç¥¨ç­›é€‰ç»“æœ_{stock_type}_{board_filter}_{datetime.now().strftime('%Y%m%d')}.csv",
                mime="text/csv"
            )
        else:
            st.warning("âš ï¸ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
    
    # é‡è¦æç¤º
    st.divider()
    st.info("""
    ğŸ›¡ï¸ TushareçœŸå®æ•°æ®ä½¿ç”¨è¯´æ˜ï¼š
    1. âœ… æ‰€æœ‰æ•°æ®å‡æ¥è‡ªTushareï¼Œä¸ºè¯åˆ¸äº¤æ˜“æ‰€çœŸå®äº¤æ˜“æ•°æ®ï¼›
    2. âš ï¸ å…è´¹ç‰ˆTushareæœ‰è¯·æ±‚é¢‘ç‡é™åˆ¶ï¼ˆæ¯åˆ†é’Ÿâ‰¤60æ¬¡ï¼‰ï¼Œæ‰¹é‡ç­›é€‰æ—¶è¯·è€å¿ƒç­‰å¾…ï¼›
    3. âš ï¸ æ•°æ®æœ‰15-30åˆ†é’Ÿå»¶è¿Ÿï¼Œéå®æ—¶è¡Œæƒ…ï¼›
    4. â— æ•°æ®ä»…ä½œå­¦ä¹ /æµ‹è¯•ä½¿ç”¨ï¼Œä¸æ„æˆä»»ä½•æŠ•èµ„å»ºè®®ã€‚
    """)

if __name__ == "__main__":

    main()
